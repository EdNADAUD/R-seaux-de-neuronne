{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.neural_network import *\n",
    "import time\n",
    "from pandas import plotting\n",
    "import sys \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = MLPClassifier(hidden_layer_sizes=1, activation='tanh',solver='sgd', batch_size=1, alpha=0, learning_rate='adaptive', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.34223871\n",
      "Iteration 2, loss = 2.30894079\n",
      "Iteration 3, loss = 2.30992471\n",
      "Iteration 4, loss = 2.30732884\n",
      "Iteration 5, loss = 2.30981282\n",
      "Iteration 6, loss = 2.30824629\n",
      "Iteration 7, loss = 2.30716977\n",
      "Iteration 8, loss = 2.30986550\n",
      "Iteration 9, loss = 2.30780249\n",
      "Iteration 10, loss = 2.30981242\n",
      "Iteration 11, loss = 2.30863604\n",
      "Iteration 12, loss = 2.30910634\n",
      "Iteration 13, loss = 2.30770937\n",
      "Iteration 14, loss = 2.30927099\n",
      "Iteration 15, loss = 2.30884875\n",
      "Iteration 16, loss = 2.30932057\n",
      "Iteration 17, loss = 2.30826088\n",
      "Iteration 18, loss = 2.30876425\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
      "Iteration 19, loss = 2.30414122\n",
      "Iteration 20, loss = 2.30371741\n",
      "Iteration 21, loss = 2.30351993\n",
      "Iteration 22, loss = 2.30352901\n",
      "Iteration 23, loss = 2.30343524\n",
      "Iteration 24, loss = 2.30345838\n",
      "Iteration 25, loss = 2.30343854\n",
      "Iteration 26, loss = 2.30328934\n",
      "Iteration 27, loss = 2.30353268\n",
      "Iteration 28, loss = 2.30343723\n",
      "Iteration 29, loss = 2.30341773\n",
      "Iteration 30, loss = 2.30348057\n",
      "Iteration 31, loss = 2.30353427\n",
      "Iteration 32, loss = 2.30340723\n",
      "Iteration 33, loss = 2.30345164\n",
      "Iteration 34, loss = 2.30359569\n",
      "Iteration 35, loss = 2.30353131\n",
      "Iteration 36, loss = 2.30340155\n",
      "Iteration 37, loss = 2.30359178\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000040\n",
      "Iteration 38, loss = 2.30217822\n",
      "Iteration 39, loss = 2.30215795\n",
      "Iteration 40, loss = 2.30215727\n",
      "Iteration 41, loss = 2.30216154\n",
      "Iteration 42, loss = 2.30215381\n",
      "Iteration 43, loss = 2.30216772\n",
      "Iteration 44, loss = 2.30217293\n",
      "Iteration 45, loss = 2.30218987\n",
      "Iteration 46, loss = 2.30213230\n",
      "Iteration 47, loss = 2.30217913\n",
      "Iteration 48, loss = 2.30213667\n",
      "Iteration 49, loss = 2.30215899\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000008\n",
      "Iteration 50, loss = 2.30188001\n",
      "Iteration 51, loss = 2.30187964\n",
      "Iteration 52, loss = 2.30188043\n",
      "Iteration 53, loss = 2.30187827\n",
      "Iteration 54, loss = 2.30188110\n",
      "Iteration 55, loss = 2.30188543\n",
      "Iteration 56, loss = 2.30187686\n",
      "Iteration 57, loss = 2.30188079\n",
      "Iteration 58, loss = 2.30187987\n",
      "Iteration 59, loss = 2.30187973\n",
      "Iteration 60, loss = 2.30187631\n",
      "Iteration 61, loss = 2.30187612\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000002\n",
      "Iteration 62, loss = 2.30182211\n",
      "Iteration 63, loss = 2.30182215\n",
      "Iteration 64, loss = 2.30182238\n",
      "Iteration 65, loss = 2.30182255\n",
      "Iteration 66, loss = 2.30182259\n",
      "Iteration 67, loss = 2.30182271\n",
      "Iteration 68, loss = 2.30182332\n",
      "Iteration 69, loss = 2.30182196\n",
      "Iteration 70, loss = 2.30182257\n",
      "Iteration 71, loss = 2.30182264\n",
      "Iteration 72, loss = 2.30182104\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 73, loss = 2.30181091\n",
      "Iteration 74, loss = 2.30181087\n",
      "Iteration 75, loss = 2.30181096\n",
      "Iteration 76, loss = 2.30181120\n",
      "Iteration 77, loss = 2.30181098\n",
      "Iteration 78, loss = 2.30181082\n",
      "Iteration 79, loss = 2.30181096\n",
      "Iteration 80, loss = 2.30181106\n",
      "Iteration 81, loss = 2.30181084\n",
      "Iteration 82, loss = 2.30181105\n",
      "Iteration 83, loss = 2.30181086\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Learning rate too small. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0, batch_size=1, hidden_layer_sizes=1,\n",
       "              learning_rate='adaptive', solver='sgd', verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
